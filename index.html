<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ramya Hebbalaguppe</title>
  
  <meta name="author" content="Ramya Hebbalaguppe">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ramya Hebbalaguppe</name>
              </p>
              <p>I'm a senior research scientist at TCS Research New Delhi, India. My primary interests are in computer vision and reliable machine learning. During my Ph.D., I investigated techniques of uncertainty quantification: Deep Neural Network Calibration, Out of Distribution detection and Generalisation in a continual learning setting, and DNN parameter optimization to reduce carbon footprint.
              </p>
              <p>
                On the computational imaging/art side of things, I have worked on High Dynamic Range Imaging that works in real-time and is a part of the image processing pipeline (JPEGs). The work was selected for the Best Student Paper award at the SPIE conference 2012 held in Burlingame, California. I have also worked on Augmented reality, specifically - layout optimization for immersive label placement, and gestural interfaces for head-mounted devices and smartphones. I have led a team for a frugal industrial inspection framework. Of late, we are working on frugal motion capture and deformation capture.</a>.
              </p>
              
              <p style="text-align:center">>
                <a href="mailto:ramya.murthy@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=IJjnjZIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/RHebbalaguppe">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/rhebbalaguppe">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/dp.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/dp.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in visual computing (computer vision, computational photography, and computer graphics) and reliable/robustness in machine learning (out-of-distribution detection, Deep neural network calibration, uncertainty quantification, continual learning).  Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
      

          <!-- Add new papers here -->



          <!-- Transfer4D  -->

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
          <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">-->  <!-- For oral papers uncomment this line -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='transfer4D_image'><video  width=100%  muted autoplay loop> <!-- Note:- Make sure to change `transfer4D_image` for the new paper -->
                <source src="images/Transfer4D-CVPR-cropped.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/Transfer4D-CVPR-cropped.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('transfer4D_image').style.opacity = "1"; // Note:- Make sure to change `transfer4D_image` for the new paper
                }

                function dreamfusion_stop() {
                  document.getElementById('transfer4D_image').style.opacity = "0"; // Note:- Make sure to change `transfer4D_image` for the new paper
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dreamfusion3d.github.io/">
                <papertitle>Transfer4D: A framework for frugal motion capture and deformation transfer</papertitle>
              </a>
              <br>
              <a href="https://shubhmaheshwari.github.io/website/">Shubh Maheshwari</a>,
              <a href="https://www.cse.iitd.ac.in/~narain/">Rahul Narain</a>,
              <strong>Ramya Hebbalaguppe</strong>,
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023 &nbsp  <!-- <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <br>
              <a href="https://transfer4d.github.io/#">project page</a>
              <!-- / <a href="">arXiv</a> -->
              <!-- / <a href="">Additional</a> -->
              <p></p>
              <p>
              Transfer4D transfers motion from a commodity depth sensor to a virtual model.
              </p>
            </td>
          </tr>
		  
          <!--\ Transfer4D  -->


          <!-- Calibration on data-diet  -->

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
          <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">-->  <!-- For oral papers uncomment this line -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/data_diet.png' width="160">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2023/html/Patra_Calibrating_Deep_Neural_Networks_Using_Explicit_Regularisation_and_Dynamic_Data_WACV_2023_paper.html">
                <papertitle>Calibrating Deep Neural Networks Using Explicit Regularisation and Dynamic Data Pruning</papertitle>
              </a>
              <br>
              <a href="https://hades-rp2010.github.io/">Rishabh Patra*</a>,
              <strong>Ramya Hebbalaguppe*</strong>,
              <a href="https://tirtharajdash.github.io/">Tirtharaj Dash</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=f70Rc2wAAAAJ">Gautam Shroff</a>,
              <a href="https://scholar.google.com/citations?user=M5MIeROF8JYC&hl=en">Lovekesh Vig</a>,
              <br>
              <em>IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2023  &nbsp  -- <font color="red"><strong>[Spotlight Presentation]</strong></font> -->
              <br>
              <a href="https://openaccess.thecvf.com/content/WACV2023/html/Patra_Calibrating_Deep_Neural_Networks_Using_Explicit_Regularisation_and_Dynamic_Data_WACV_2023_paper.html/#">project page</a>
              <!-- / <a href="">arXiv</a> -->
              <!-- / <a href="">Additional</a> -->
              <p></p>
              <p>
              We demonstrate state-of-the-art Deep Neural Network calibration performance via proposing a differentiable loss term
that can be used effectively in gradient descent optimisation and dynamic data pruning strategy not only enhances legitimate
high confidence samples to enhance trust in DNN classifiers but also reduce the training time for calibration.
              </p>
            </td>
          </tr>
      
          <!--\ MDCA  -->


                    <!-- MDCA -->

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
          <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">-->  <!-- For oral papers uncomment this line -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/stitch_in_time.png' width="160">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/mdca-loss/MDCA-Calibration">
                <papertitle> A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration </papertitle>
              </a>
              <br>
              <strong>Ramya Hebbalaguppe*</strong>,
              <strong>Jatin Prakash*</strong>,
              <strong>Jatin Prakash*</strong>,
              <a href="https://www.cse.iitd.ac.in/~chetan/">Chetan Arora</a>,
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2022  &nbsp  -- <font color="red"><strong>[ORAL Presentation]</strong></font> -->
              <br>
              <a href="https://github.com/mdca-loss/MDCA-Calibration/#">project page</a>
              <!-- / <a href="">arXiv</a> -->
              <!-- / <a href="">Additional</a> -->
              <p></p>
              <p>
              We propose a novel auxiliary loss function: Multi-class Difference in Confidence and Accuracy (MDCA) for Deep Neural Network calibration. The loss can be combined with any application specific classification losses for image, NLP, Speech domains. We also demonstrate the utility of the loss in semantic segmentation tasks.
              </p>
            </td>
          </tr>
      
          <!--\ MDCA  -->


        </tbody></table>

				<!-- Uncomment to add misc section -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody> -->
					
        <!-- Uncomment to Area chair info -->
        <!-- 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr> -->

				<!-- Uncomment to add blog post info	 -->
        <!--
          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr> -->
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Website inspired from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's</a> and <a href="https://leonidk.com/">Leonid Keselman</a>'s webpage page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
