<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ramya Hebbalaguppe</title>
  
  <meta name="author" content="Ramya Hebbalaguppe">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ramya Hebbalaguppe</name>
              </p>
              <p> I work as a research scientist, Deep Learning and Artificial Intelligence Group, TCS Research in New Delhi, India, where my main focus is on computer vision and trustworthy machine learning. My doctoral research advised by <a href="https://www.cse.iitd.ac.in/~chetan/">Prof. Chetan Arora</a> at IIT Delhi is centered on proposing novel methods for trustworthy/reliable deep neural networks (DNNs)
                </p>

                <p>  Prior to this, I was fortunate to be working with <a href="https://sites.google.com/site/ramakrishnakakarala/research?authuser=0">Prof. Ramakrishna Kakarala</a> at Nanyang Technological University on High Dynamic Range Imaging algorithms which formed a part of the image processing pipeline aimed at smartphone cameras.  Our research was recognized with the Best Student Paper award at the 2012 SPIE conference in Burlingame, California. I completed my master's degree at DCUs School of Electronic Engineering and Computing in 2014, advised by <a href="https://www.insight-centre.org/our-team/prof-noel-oconnor/">Prof. Noel O'Connor</a> and <a href="https://www.dcu.ie/insight/people/alan-smeaton">Prof. Alan Smeaton</a>. I focused on reducing false alarms in surveillance camera networks. As a result of this work, a portion of our research was licensed to Netwatch Systems.
              </p>
              <p>
                In June 2015, I started working as a research scientist at TCS Research. In addition to my work on computer vision and machine learning, I have also been involved in various projects related to augmented reality. Specifically, I have focused on optimizing the layout of labels for immersive experiences and developing gestural interfaces for head-mounted devices and smartphones. As a team leader, I have overseen the development of a cost-effective industrial inspection framework. Recently, my team has been working on developing affordable solutions for motion capture and deformation capture.</a>
              </p>
              
              <p style="text-align:center">>
                <a href="mailto:ramya.murthy@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=IJjnjZIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/RHebbalaguppe">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/rhebbalaguppe">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/playa.png"><img style="width:120%;max-width:120%" alt="profile photo" src="images/playa.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in visual computing (computer vision, computational photography, and computer graphics) and reliable/robustness in machine learning (out-of-distribution detection, Deep neural network calibration, uncertainty quantification, continual learning).  Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
      

          <!-- Add new papers here -->



          <!-- Transfer4D  -->

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
          <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">-->  <!-- For oral papers uncomment this line -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='transfer4D_image'><video  width=100%  muted autoplay loop> <!-- Note:- Make sure to change `transfer4D_image` for the new paper -->
                <source src="images/Transfer4D-CVPR-cropped.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/Transfer4D-CVPR-cropped.jpeg' width="160" height ="200">
              </div>
              <script type="text/javascript">
                function dreamfusion_start() {
                  document.getElementById('transfer4D_image').style.opacity = "1"; // Note:- Make sure to change `transfer4D_image` for the new paper
                }

                function dreamfusion_stop() {
                  document.getElementById('transfer4D_image').style.opacity = "0"; // Note:- Make sure to change `transfer4D_image` for the new paper
                }
                dreamfusion_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dreamfusion3d.github.io/">
                <papertitle>Transfer4D: A framework for frugal motion capture and deformation transfer</papertitle>
              </a>
              <br>
              <a href="https://shubhmaheshwari.github.io/website/">Shubh Maheshwari</a>,
              <a href="https://www.cse.iitd.ac.in/~narain/">Rahul Narain</a>,
              <strong>Ramya Hebbalaguppe</strong>,
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023 &nbsp  <!-- <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <br>
              <a href="https://transfer4d.github.io/#">project page</a>
              <!-- / <a href="">arXiv</a> -->
              <!-- / <a href="">Additional</a> -->
              <p></p>
              <p>
              Transfer4D transfers motion from a commodity depth sensor to a virtual model. The goal of our work is to democratize animation transfer using commodity depth sensors and alleviate the animators effort by automating the rigging and animation transfer process.
              </p>
            </td>
          </tr>
		  
          <!--\ Transfer4D  -->


          <!-- Calibration on data-diet  -->

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
           <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/data_diet.png' width="160">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/WACV2023/html/Patra_Calibrating_Deep_Neural_Networks_Using_Explicit_Regularisation_and_Dynamic_Data_WACV_2023_paper.html">
                <papertitle>Calibrating Deep Neural Networks Using Explicit Regularisation and Dynamic Data Pruning</papertitle>
              </a>
              <br>
              <a href="https://hades-rp2010.github.io/">Rishabh Patra*</a>,
              <strong>Ramya Hebbalaguppe*</strong>,
              <a href="https://tirtharajdash.github.io/">Tirtharaj Dash</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=f70Rc2wAAAAJ">Gautam Shroff</a>,
              <a href="https://scholar.google.com/citations?user=M5MIeROF8JYC&hl=en">Lovekesh Vig</a>,
              <br>
              <em>IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2023  &nbsp  -- <font color="red"><strong>[Spotlight Presentation]</strong></font> 
              <br>
              <a href="https://openaccess.thecvf.com/content/WACV2023/html/Patra_Calibrating_Deep_Neural_Networks_Using_Explicit_Regularisation_and_Dynamic_Data_WACV_2023_paper.html/#">project page</a>
              <!-- / <a href="">arXiv</a> -->
              <!-- / <a href="">Additional</a> -->
              <p></p>
              <p>
              We demonstrate state-of-the-art Deep Neural Network calibration performance via proposing a differentiable loss term
that can be used effectively in gradient descent optimisation and dynamic data pruning strategy not only enhances legitimate
high confidence samples to enhance trust in DNN classifiers but also reduce the training time for calibration.
              </p>
            </td>
          </tr>
      
<!-- CnC -->

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
           <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/CnC.png' width="160">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/cnc-ood/">
                <papertitle>A Novel Data Augmentation Technique for Out-of-Distribution Sample Detection using Compounded Corruptions</papertitle>
              </a>
              <br>
              <strong>Ramya Hebbalaguppe</strong>,
              <a href="https://soumya1612-rasha.github.io/Soumya/">Soumya Suvra Ghosal</a>,
              <a href="https://in.linkedin.com/in/jatin-prakash-6874b91a4">Jatin Prakash</a>,
              <a href="https://sites.google.com/view/harshad/home">Harshad Khadilkar</a>,
              <a href="https://www.cse.iitd.ac.in/~chetan/">Chetan Arora</a>,
              
              <br>
              <em>European Conference on Machine Learning </em>, 2022 &nbsp  <!-- <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <br>
              <a href="https://github.com/cnc-ood/#">project page</a>
              <!-- / <a href="">arXiv</a> -->
              <!-- / <a href="">Additional</a> -->
              <p></p>
              <p>
              We propose a novel Compounded Corruption(CnC) technique for the Out-of-Distribution data augmentation. One of the major advantages of CnC is that it does not require any hold-out data apart from the training set. Our extensive comparison with 20 methods from the major conferences in last 4 years show that a model trained using CnC based data augmentation, significantly outperforms SOTA, both in terms of OOD detection accuracy as well as inference time.
              </p>
            </td>
          </tr>
      
          <!--\ Transfer4D  -->


                    <!-- MDCA -->

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
           <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/stitch_in_time.png' width="160">
              </div>
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/mdca-loss/MDCA-Calibration">
                <papertitle> A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration </papertitle>
              </a>
              <br>
              <strong>Ramya Hebbalaguppe*</strong>,
              <a href="https://in.linkedin.com/in/jatin-prakash-6874b91a4">Jatin Prakash</a>,
              <strong>Neelabh Madan*</strong>,
              <a href="https://www.cse.iitd.ac.in/~chetan/">Chetan Arora</a>,
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2022  &nbsp  -- <font color="red"><strong>[ORAL Presentation]</strong></font> 
              <br>
              <a href="https://github.com/mdca-loss/MDCA-Calibration/#">project page</a>
              <!-- / <a href="">arXiv</a> -->
              <!-- / <a href="">Additional</a> -->
              <p></p>
              <p>
              We propose a novel auxiliary loss function: Multi-class Difference in Confidence and Accuracy (MDCA) for Deep Neural Network calibration. The loss can be combined with any application specific classification losses for image, NLP, Speech domains. We also demonstrate the utility of the loss in semantic segmentation tasks.
              </p>
            </td>
          </tr>
      
          <!--\ MDCA  -->


        </tbody></table>

        <section width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <h2>Current team at TCS Research, IIT Delhi</h2>
          <!-- <ul style="list-style-type: none;">   -->
          <ul>
            <li><a style="text-decoration: none;" href="https://scholar.google.co.in/citations?hl=en&user=gpsZ7p8AAAAJ&view_op=list_works&sortby=pubdate"> Dr. Swapna Agarwal (ISI Kolkata) <strong>Topic:</strong> Shape correspondence </a></li>
            <li><a style="text-decoration: none;" href="https://shubhmaheshwari.github.io/"> Shubh Maheshwari (IIIT Hyderabad) (Full time researcher)<strong>Topic:</strong> <a href="https://transfer4d.github.io/">Frugal motion capture and animation transfer </a></li>
            <li><a style="text-decoration: none;" href="https://researchweb.iiit.ac.in/~jai.bardhan/"> Jai Bhardhan (IIIT Hyderabad) (Predoc Fellow)<strong>Topic:</strong>  Skeletonization and Shape correspondence </a></li>
            <li><a style="text-decoration: none;" >  Aravind Udupa (Maths and Computing, IITD (Summer'23 Intern)) <strong>Topic:</strong> Skeletonization using Local seperators </a></li>
                       

            <li><a style="text-decoration: none;" > Adarsh Kappiyath (Indian Institute of Space Science and Technology) (Predoc Fellow) <strong>Topic:</strong> Continual Learning </a></li>
            <li><a style="text-decoration: none;" >  Goirik Chakrabarty (IISER (Pune)/IISc) (Predoc Fellow) <strong>Topic:</strong> Few Shot continual learning </a></li>
            <li><a style="text-decoration: none;" > Anmol Garg (IISc, Bangalore) (Dec'22 and Summer'23 Intern) <strong>Topic:</strong> Continual Learning </a></li>

          </ul>
        </section>


        <section width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
          <h2>Supervised the following full-time researchers/research interns</h2>
          <ul>     
            <li><a style="text-decoration: none;"href="https://surabhisnath.github.io"> Surabhi Nath &#8594 Doctoral student at the Max Planck School of Cognition and the MPI for Biological Cybernetics </a></li>     
            <li><a style="text-decoration: none;" > Meghal Dani &#8594 Doctoral student at IMPRS-IS, Max Planck School </a></li>
            <li><a style="text-decoration: none;" href="https://gaurav16gupta.github.io/"> Gaurav Gupta &#8594 Doctoral student at Rice University</a></li>
            <li><a style="text-decoration: none;" href="https://research.manchester.ac.uk/en/persons/apoorv.khattar-postgrad"> Apoorv Khattar &#8594 Doctoral student at University of Manchester, UK</a></li>
            <li><a style="text-decoration: none;" > Neel Rakholia &#8594 Masters Student at Stanford</a></li>
            <li><a style="text-decoration: none;" href="https://sharanry.github.io/">  Sharan Yalburgi &#8594 Visiting researcher at MIT proabilistic ML project</a></li>
            <li><a style="text-decoration: none;" href="https://srihegde.github.io/"> Srinidhi Hegde &#8594 Masters Student at UMD</a></li>
            <li><a style="text-decoration: none;" href="https://shubhmaheshwari.github.io/"> Shubh Maheshwari &#8594 Graduate student at UCSD</a></li>

            <li><a style="text-decoration: none;" > Pranay Gupta &#8594 Masters student at CMU</a></li>
            <li><a style="text-decoration: none;" > Jitender Maurya &#8594 Researcher, Toshiba</a></li>
            <li><a style="text-decoration: none;" > Archie Gupta &#8594 SDE, Microsoft</a></li>
            <li><a style="text-decoration: none;" > Varun Jain &#8594 Masters student at CMU &#8594 Microsoft Fellow</a></li>
            <li><a style="text-decoration: none;" href="https://www.linkedin.com/in/shreyashmohatta/"> Shreyash Mohatta &#8594 Masters student at NCSU</a></li>
            <li><a style="text-decoration: none;" href="https://www.linkedin.com/in/addityapopli/?originalSubdomain=in"> Additya Popli &#8594 SDE at Google</a></li>
            <li><a style="text-decoration: none;" > Kshitijz Jain &#8594 Grad student at IITD</a></li>
            
            
            <li><a style="text-decoration: none;" > Soumya Suvra Ghosal &#8594 Masters Student at University of Wisconsin</a></li>
            <li><a style="text-decoration: none;" href="https://in.linkedin.com/in/jatin-prakash-6874b91a4"> Jatin Prakash &#8594 Research Fellow, MSR</a></li>
            <li><a style="text-decoration: none;" > Neelabh Madan &#8594 Research Fellow, MSR</a></li>
            <li><a style="text-decoration: none;" > Gaurav Garg &#8594  Accenture</a></li>
            
            <li><a style="text-decoration: none;" > Ramakrishna Perla &#8594 TTEC Digital</a></li>
            <li><a style="text-decoration: none;" > Rishabh Patra  &#8594 SDE Amazon </a></li>

          </ul>
        </section>

				<!-- Uncomment to add misc section -->
        <!--, such as confidence calibration, detecting out-of-distribution sample to abstain from making decisions on unknown classes, and improving generalization in a continual learning setting. Additionally, my work also has been in optimizing DNN parameters to obtain reliable light weight models. -->
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody> -->
					
        <!-- Uncomment to Area chair info -->
        <!-- 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr> -->

				<!-- Uncomment to add blog post info	 -->
        <!--
          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr> -->
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Website inspired from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
